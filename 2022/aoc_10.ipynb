{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce1f47-fa92-4dff-9159-7a03e08e4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col as c, lit as l\n",
    "from pyspark.sql import Column\n",
    "from typing import List\n",
    "from pyspark.sql import Window as W\n",
    "from functools import reduce\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0682ef-5906-47eb-ace9-79ada1fc7eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"AoC_2022_10[2]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5abcc04-b5dc-446c-a1d7-db48641d3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_transformer(e: Column) -> Column:\n",
    "    splits = F.split(e, \" \")\n",
    "    op = splits[0]\n",
    "    val = F.coalesce(splits[1].cast(\"int\"), l(0))\n",
    "    return F.struct(op.alias(\"op\"), val.alias(\"val\"))\n",
    "\n",
    "\n",
    "inputs = (spark.read.text(\"./data/aoc_10.txt\", wholetext=True)\n",
    "          .withColumn(\"fn\", l(\"fn\"))\n",
    "          .withColumn(\"value\", F.split(\"value\", \"\\n\"))\n",
    "          .withColumn(\"value\", F.transform(\"value\", lambda e: value_transformer(e)))\n",
    "          .select(\"fn\", F.posexplode(\"value\").alias(\"rn\", \"op_val\")).select(\"fn\", \"rn\", \"op_val.*\"))\n",
    "inputs.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61eb5b6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# sample = [(1, \"a\", \"noop\", 0),\n",
    "#           (2, \"a\", \"noop\", 0),\n",
    "#           (3, \"a\", \"addx\", 5),\n",
    "#           (4, \"a\", \"noop\", 0),\n",
    "#           (5, \"a\", \"noop\", 0),\n",
    "#           (6, \"a\", \"addx\", 6), ]\n",
    "#\n",
    "# inputs = spark.createDataFrame(sample, (\"rn\", \"fn\", \"op\", \"val\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "noop = l(\"noop\")\n",
    "addx = l(\"addx\")\n",
    "\n",
    "cycles_map = F.create_map(noop, l(1), addx, l(2))\n",
    "\n",
    "ws = W.partitionBy(\"fn\").orderBy(\"rn\").rowsBetween(W.unboundedPreceding, W.currentRow)\n",
    "\n",
    "val_after_cycle = (F.sum(\"val\").over(ws) + 1).alias(\"val_after_cycle\")\n",
    "val_before_cycle = (val_after_cycle - c(\"val\")).alias(\"val_before_cycle\")\n",
    "cycles = cycles_map[c(\"op\")].alias(\"cycles\")\n",
    "cycles_end = F.sum(cycles).over(ws).alias(\"cycles_end\")\n",
    "cycles_start = (cycles_end - cycles + 1).alias(\"cycles_start\")\n",
    "\n",
    "eval_cond = F\n",
    "for r in [20, 60, 100, 140, 180, 220]:\n",
    "    eval_cond = (eval_cond.when(l(r).between(c(\"cycles_start\"), c(\"cycles_end\")), r * c(\"val_before_cycle\")))\n",
    "\n",
    "eval_cond = eval_cond.otherwise(0)\n",
    "\n",
    "strengths = (inputs.select(\"*\", cycles, val_before_cycle, val_after_cycle, cycles_start, cycles_end)\n",
    "             .select(\"*\", eval_cond.alias(\"strength\")))\n",
    "strengths.groupby(\"fn\").agg(F.sum(\"strength\").alias(\"total_strength\")).head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b4c63cb2d918b6f68ee143ad2028ff4f90f6ba246f1c2fb2516c69c9e93e5d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
